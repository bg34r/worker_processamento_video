# Video Processer Worker

Este projeto √© um sistema de processamento de v√≠deos que utiliza AWS S3 e SQS via LocalStack para extrair frames de v√≠deos e gerar arquivos ZIP com os frames extra√≠dos.

## üìã √çndice

- [Arquitetura](#-arquitetura)
- [Pr√©-requisitos](#-pr√©-requisitos)
- [Instala√ß√£o](#-instala√ß√£o)
- [Configura√ß√£o](#-configura√ß√£o)
- [Execu√ß√£o](#-execu√ß√£o)
- [Testando o Sistema](#-testando-o-sistema)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [API Reference](#-api-reference)

## üèó Arquitetura

O sistema funciona com os seguintes componentes:

1. **LocalStack**: Simula servi√ßos AWS (S3 e SQS) localmente
2. **S3 Bucket**: Armazena v√≠deos de entrada e ZIPs de sa√≠da
3. **SQS Queue**: Fila de mensagens para processamento de v√≠deos
4. **Video Processer Worker**: Aplica√ß√£o que consome mensagens e processa v√≠deos
5. **FFmpeg**: Extrai frames dos v√≠deos
6. **Kafka**: Recebe notifica√ß√µes de sucesso/falha do processamento

### Responsabilidades

> **‚ö†Ô∏è IMPORTANTE**: Este reposit√≥rio cont√©m apenas os **workers de processamento**. 

**‚úÖ O que os workers fazem:**
- Consumir mensagens da fila SQS
- Baixar v√≠deos j√° existentes no S3
- Extrair frames dos v√≠deos
- Criar arquivos ZIP com os frames
- Fazer upload dos ZIPs processados para S3
- Enviar notifica√ß√µes Kafka sobre sucesso/falha

**‚ùå O que os workers N√ÉO fazem:**
- Upload de v√≠deos originais para S3 (responsabilidade do servi√ßo de upload)
- Autentica√ß√£o de usu√°rios
- API REST para recebimento de v√≠deos
- Interface web para upload

### Fluxo de Processamento

```
[Servi√ßo Upload] ‚Üí V√≠deo S3 ‚Üí Mensagem SQS ‚Üí Worker ‚Üí Frames ‚Üí ZIP S3 ‚Üí Kafka Notification
```

## üìã Pr√©-requisitos

- [Docker Desktop](https://www.docker.com/products/docker-desktop/)
- [Go 1.21+](https://golang.org/dl/)
- [Git Bash](https://git-scm.com/downloads) (para executar scripts bash no Windows)
- [FFmpeg](https://ffmpeg.org/download.html) (instalado no sistema)

## üöÄ Instala√ß√£o

### 1. Clone o reposit√≥rio

```bash
git clone <url-do-repositorio>
cd worker
```

### 2. Instale as depend√™ncias Go

```bash
go mod download
```

### 3. Configure o LocalStack

Certifique-se de que o Docker Desktop est√° rodando, ent√£o execute:

```bash
# Dar permiss√£o de execu√ß√£o ao script (se necess√°rio)
chmod +x setup-localstack.sh

# Configurar LocalStack
bash ./setup-localstack.sh
```

Este script ir√°:
- Parar containers existentes
- Iniciar o LocalStack
- Criar bucket S3 (`video-bucket`)
- Criar fila SQS (`video-processing-queue`)

## ‚öôÔ∏è Configura√ß√£o

### Estrutura do docker-compose.yml

```yaml
services:
  localstack:
    image: localstack/localstack:2.3
    container_name: localstack-main
    ports:
      - "4566:4566"
    environment:
      - SERVICES=s3,sqs
      - DEBUG=1
      - LOCALSTACK_HOST=localhost
      - DOCKER_HOST=unix:///var/run/docker.sock
    volumes:
      - "localstack-data:/var/lib/localstack"
      - "/var/run/docker.sock:/var/run/docker.sock"

volumes:
  localstack-data:
```

### Vari√°veis de Ambiente

O sistema usa as seguintes credenciais para o LocalStack:
- `AWS_ACCESS_KEY_ID=test`
- `AWS_SECRET_ACCESS_KEY=test`
- `AWS_DEFAULT_REGION=us-east-1`

## üèÉ‚Äç‚ôÇÔ∏è Execu√ß√£o

### Modo Desenvolvimento (Worker √∫nico)

#### 1. Inicie o LocalStack

```bash
# Se n√£o executou o setup ainda
bash ./setup-localstack.sh

# Ou apenas para iniciar
docker-compose up -d
```

#### 2. Verifique se o LocalStack est√° funcionando

```bash
curl http://localhost:4566/_localstack/health
```

#### 3. Execute o Worker

```bash
go run cmd/server/main.go
```

Voc√™ deve ver a mensagem:
```
üöÄ video-processer-worker-1 (ID: 1) iniciando...
‚úÖ video-processer-worker-1 iniciado - monitorando fila SQS...
```

### Modo Produ√ß√£o (M√∫ltiplos Workers) üöÄ

#### Usando Scripts de Gerenciamento

**Windows (PowerShell):**
```powershell
# Iniciar 3 workers (padr√£o)
.\manage-workers.ps1 start

# Escalar para 5 workers
.\manage-workers.ps1 scale -Workers 5

# Ver status dos workers
.\manage-workers.ps1 status

# Ver logs do worker espec√≠fico
.\manage-workers.ps1 logs -WorkerId 2

# Parar todos os workers
.\manage-workers.ps1 stop
```

**Linux/macOS (Bash):**
```bash
# Dar permiss√£o de execu√ß√£o
chmod +x manage-workers.sh

# Iniciar 3 workers (padr√£o)
./manage-workers.sh start

# Escalar para 5 workers
./manage-workers.sh scale 5

# Ver status dos workers
./manage-workers.sh status

# Ver logs do worker espec√≠fico
./manage-workers.sh logs 2

# Parar todos os workers
./manage-workers.sh stop
```

#### Usando Docker Compose Diretamente

```bash
# Iniciar todos os 3 workers configurados
docker-compose up -d

# Iniciar workers espec√≠ficos
docker-compose up -d video-processer-worker-1 video-processer-worker-2

# Ver status
docker-compose ps

# Ver logs de todos os workers
docker-compose logs -f

# Ver logs de worker espec√≠fico
docker-compose logs -f video-processer-worker-1

# Parar todos
docker-compose down
```

### üìä Monitoramento em Tempo Real

```bash
# Status detalhado dos workers
docker stats video-worker-1 video-worker-2 video-worker-3

# Logs combinados com timestamps
docker-compose logs --timestamps --follow

# Monitorar uso de recursos
watch -n 2 'docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}"'
```

## üß™ Testando o Sistema com M√∫ltiplos Workers

### Teste de Escalabilidade - Processamento Paralelo

#### 1. Inicie m√∫ltiplos workers

```powershell
# Windows - Iniciar 3 workers
.\manage-workers.ps1 start

# Linux/macOS
./manage-workers.sh start
```

#### 2. Simula√ß√£o de m√∫ltiplos v√≠deos para teste (apenas para desenvolvimento)

> **‚ö†Ô∏è IMPORTANTE**: Os workers de processamento **N√ÉO** s√£o respons√°veis por fazer upload de v√≠deos para o S3. 
> Esta responsabilidade √© do servi√ßo de upload em outro reposit√≥rio. 
> Os comandos abaixo s√£o **apenas para testes** durante o desenvolvimento.

```bash
# APENAS PARA TESTE - simular v√≠deos j√° existentes no S3
# Em produ√ß√£o, os v√≠deos chegam via servi√ßo de upload
docker cp "C:\Users\Caminho\Para\video\video1.mp4" localstack-main:/tmp/video1.mp4
docker cp "C:\Users\Caminho\Para\video\video2.mp4" localstack-main:/tmp/video2.mp4
docker cp "C:\Users\Caminho\Para\video\video3.mp4" localstack-main:/tmp/video3.mp4

# APENAS PARA TESTE - simular v√≠deos no S3 (normalmente feito pelo servi√ßo de upload)
docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 s3 cp /tmp/video1.mp4 s3://video-service-bucket/
docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 s3 cp /tmp/video2.mp4 s3://video-service-bucket/
docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 s3 cp /tmp/video3.mp4 s3://video-service-bucket/
```

#### 3. Enviar mensagens SQS para processamento paralelo

```bash
# Processar todos os v√≠deos simultaneamente
docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 sqs send-message --queue-url http://localhost:4566/000000000000/video-processing-queue --message-body '{"video_key":"video1.mp4","video_id":"video1_001"}'

docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 sqs send-message --queue-url http://localhost:4566/000000000000/video-processing-queue --message-body '{"video_key":"video2.mp4","video_id":"video2_001"}'

docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 sqs send-message --queue-url http://localhost:4566/000000000000/video-processing-queue --message-body '{"video_key":"video3.mp4","video_id":"video3_001"}'
```

#### 4. Monitorar processamento paralelo

Os workers devem mostrar mensagens identificadas:
```
üé¨ video-processer-worker-1 - Processando v√≠deo: video1.mp4
üé¨ video-processer-worker-2 - Processando v√≠deo: video2.mp4
üé¨ video-processer-worker-3 - Processando v√≠deo: video3.mp4
‚öôÔ∏è video-processer-worker-1 - Extraindo frames do v√≠deo: video1.mp4
‚öôÔ∏è video-processer-worker-2 - Extraindo frames do v√≠deo: video2.mp4
üì¶ video-processer-worker-3 - Criando arquivo ZIP: video3_frames.zip
üéâ video-processer-worker-1 - Processamento conclu√≠do: video1.mp4 -> processed/video1_frames.zip
```

### Teste com V√≠deos Reais (apenas desenvolvimento)

> **‚ö†Ô∏è IMPORTANTE**: Em produ√ß√£o, os v√≠deos s√£o enviados pelo **servi√ßo de upload** (reposit√≥rio separado) via API REST.
> Os comandos abaixo s√£o **apenas para testes locais** dos workers de processamento.

#### 1. Simular v√≠deo j√° no S3 (para teste)

```bash
# APENAS PARA TESTE - Em produ√ß√£o isso √© feito pelo servi√ßo de upload
docker cp "C:\Users\Caminho\Para\video\nomeDoVideo0.mp4" localstack-main:/tmp/nomeDoVideo0.mp4

# APENAS PARA TESTE - Simular upload feito pelo outro servi√ßo
docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 s3 cp /tmp/nomeDoVideo0.mp4 s3://video-service-bucket/
```

#### 2. Testar com m√∫ltiplos v√≠deos (desenvolvimento)

```bash
# APENAS PARA TESTE - Simular m√∫ltiplos v√≠deos j√° enviados pelo servi√ßo de upload
docker cp "C:\Users\Caminho\Para\video\nomeDoVideo1.mp4" localstack-main:/tmp/nomeDoVideo1.mp4
docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 s3 cp /tmp/nomeDoVideo1.mp4 s3://video-service-bucket/

docker cp "C:\Users\Caminho\Para\video\nomeDoVideo2.mp4" localstack-main:/tmp/nomeDoVideo2.mp4
docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 s3 cp /tmp/nomeDoVideo2.mp4 s3://video-service-bucket/
```

#### 3. Verificar v√≠deos no bucket

```bash
docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 s3 ls s3://video-bucket/
```

Resultado esperado:
```
2025-09-23 23:40:08    2317191 nomeDoVideo0.mp4
2025-09-23 23:40:18   18542096 nomeDoVideo1.mp4
2025-09-23 23:40:30    4630949 nomeDoVideo2.mp4
```

#### 4. Enviar mensagens para processamento

```bash
# Processar nomeDoVideo0.mp4
docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 sqs send-message --queue-url http://localhost:4566/000000000000/video-processing-queue --message-body '{"video_key":"nomeDoVideo0.mp4","video_id":"nomeDoVideo0_001"}'

# Processar nomeDoVideo1.mp4
docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 sqs send-message --queue-url http://localhost:4566/000000000000/video-processing-queue --message-body '{"video_key":"nomeDoVideo1.mp4","video_id":"nomeDoVideo1_001"}'

# Processar nomeDoVideo2.mp4
docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 sqs send-message --queue-url http://localhost:4566/000000000000/video-processing-queue --message-body '{"video_key":"nomeDoVideo2.mp4","video_id":"nomeDoVideo2_001"}'
```

#### 5. Monitorar o processamento

O worker deve mostrar mensagens como:
```
2025/09/23 20:41:05 Processando v√≠deo: nomeDoVideo0.mp4
2025/09/23 20:41:05 Processamento conclu√≠do: nomeDoVideo0.mp4 -> processed/nomeDoVideo0_frames.zip
```

#### 6. Verificar resultados

```bash
# Ver todos os arquivos processados
docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 s3 ls s3://video-bucket/ --recursive
```

Resultado esperado:
```
2025-09-23 23:40:08    2317191 nomeDoVideo0.mp4
2025-09-23 23:40:18   18542096 nomeDoVideo1.mp4
2025-09-23 23:41:05   11899270 processed/nomeDoVideo0_frames.zip
2025-09-23 23:41:20   48835647 processed/nomeDoVideo1_frames.zip
2025-09-23 23:41:28   11288170 processed/nomeDoVideo2_frames.zip
2025-09-23 23:40:30    4630949 nomeDoVideo2.mp4
```

#### 7. Baixar arquivo processado

```bash
# Baixar ZIP de frames
docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 s3 cp s3://video-bucket/processed/nomeDoVideo0_frames.zip /tmp/bamboo_frames.zip

# Copiar para o host
docker cp localstack-main:/tmp/nomeDoVideo0_frames.zip ./nomeDoVideo0_frames.zip
```

#### 8. Verificar fila vazia

```bash
# Verificar se n√£o h√° mais mensagens na fila
docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 sqs receive-message --queue-url http://localhost:4566/000000000000/video-processing-queue
```

Se n√£o retornar nenhuma mensagem, significa que todas foram processadas com sucesso.

## üìÅ Estrutura do Projeto

```
worker/
‚îú‚îÄ‚îÄ cmd/
‚îÇ   ‚îî‚îÄ‚îÄ server/
‚îÇ       ‚îî‚îÄ‚îÄ main.go              # Aplica√ß√£o principal
‚îú‚îÄ‚îÄ internal/
‚îÇ   ‚îú‚îÄ‚îÄ domain/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entities/            # Entidades do dom√≠nio
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ services/            # Servi√ßos de neg√≥cio
‚îÇ   ‚îî‚îÄ‚îÄ infrastructure/
‚îÇ       ‚îú‚îÄ‚îÄ queue/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ sqs_service.go   # Servi√ßo SQS
‚îÇ       ‚îú‚îÄ‚îÄ storage/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ s3_service.go    # Servi√ßo S3
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ zip_service.go   # Servi√ßo de compacta√ß√£o
‚îÇ       ‚îî‚îÄ‚îÄ video/
‚îÇ           ‚îî‚îÄ‚îÄ ffmpeg_service.go # Extra√ß√£o de frames
‚îú‚îÄ‚îÄ outputs/                     # Arquivos ZIP gerados
‚îú‚îÄ‚îÄ temp/                        # Arquivos tempor√°rios
‚îú‚îÄ‚îÄ docker-compose.yml           # Configura√ß√£o LocalStack
‚îú‚îÄ‚îÄ setup-localstack.sh          # Script de configura√ß√£o
‚îú‚îÄ‚îÄ go.mod                       # Depend√™ncias Go
‚îî‚îÄ‚îÄ README.md                    # Este arquivo
```

## üìö API Reference

### Servi√ßos Principais

#### S3Service
- `NewS3Service(bucket string)`: Cria novo servi√ßo S3
- `DownloadVideo(key, localPath string)`: Baixa v√≠deo do S3
- `UploadZip(localPath, key string)`: Faz upload de ZIP para S3
- `ListVideos()`: Lista v√≠deos no bucket

#### SQSService
- `NewSQSService(queueURL string)`: Cria novo servi√ßo SQS
- `ReceiveMessages()`: Recebe mensagens da fila
- `DeleteMessage(receiptHandle string)`: Remove mensagem processada
- `SendMessage(videoKey string)`: Envia nova mensagem

#### Formato da Mensagem SQS

```json
{
  "video_key": "nome_do_video.mp4",
  "video_id": "identificador_unico"
}
```

## üõ† Comandos √öteis

### LocalStack
```bash
# Iniciar
docker-compose up -d

# Parar
docker-compose down

# Ver logs
docker-compose logs localstack

# Status da sa√∫de
curl http://localhost:4566/_localstack/health
```

### S3 Operations
```bash
# Listar buckets
docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 s3 ls

# Listar arquivos no bucket (v√≠deos originais e ZIPs processados)
docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 s3 ls s3://video-service-bucket/ --recursive

# APENAS PARA TESTE - Upload de arquivo (normalmente feito pelo servi√ßo de upload)
docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 s3 cp /caminho/arquivo s3://video-service-bucket/
```

### SQS Operations
```bash
# Listar filas
docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 sqs list-queues

# Enviar mensagem
docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 sqs send-message --queue-url http://localhost:4566/000000000000/video-processing-queue --message-body '{"video_key":"video.mp4","video_id":"123"}'

# Receber mensagens
docker exec -e AWS_ACCESS_KEY_ID=test -e AWS_SECRET_ACCESS_KEY=test -e AWS_DEFAULT_REGION=us-east-1 localstack-main aws --endpoint-url=http://localhost:4566 sqs receive-message --queue-url http://localhost:4566/000000000000/video-processing-queue
```

## üêõ Troubleshooting

### Erro: "NoCredentialProviders"
- **Problema**: Credenciais AWS n√£o configuradas nos servi√ßos
- **Solu√ß√£o**: Verificar se os servi√ßos S3 e SQS t√™m `credentials.NewStaticCredentials("test", "test", "")`

### Erro: "Container not running"
- **Problema**: LocalStack n√£o est√° executando
- **Solu√ß√£o**: `docker-compose up -d` e verificar `docker ps`

### Erro: "Device or resource busy"
- **Problema**: Conflito de volumes do Docker
- **Solu√ß√£o**: `docker-compose down --volumes` e `docker volume prune -f`

### FFmpeg n√£o encontrado
- **Problema**: FFmpeg n√£o instalado no sistema
- **Solu√ß√£o**: Instalar FFmpeg e adicionar ao PATH do sistema

## ü§ù Contribui√ß√£o

1. Fa√ßa fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/nova-feature`)
3. Commit suas mudan√ßas (`git commit -am 'Adiciona nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## ÔøΩ Qualidade de C√≥digo e Testes

### Cobertura de Testes

Este projeto mant√©m padr√µes rigorosos de qualidade:

- **Cobertura m√≠nima do reposit√≥rio**: 60%
- **Cobertura m√≠nima para c√≥digo novo**: 40%
- **An√°lise est√°tica**: SonarQube

### Executando Testes Localmente

```bash
# PowerShell (Windows)
.\test-coverage.ps1

# Bash (Linux/macOS)  
./test-coverage.sh

# Apenas testes (sem SonarQube)
.\test-coverage.ps1 -OnlyTests

# Com SonarQube
.\test-coverage.ps1 -SonarToken "seu_token_aqui"
```

### Relat√≥rios Gerados

- `coverage.out` - Cobertura para SonarQube
- `coverage.html` - Relat√≥rio visual de cobertura  
- `coverage_report.txt` - Relat√≥rio texto

### CI/CD Pipeline

O projeto utiliza GitHub Actions com:

1. **Testes automatizados** com LocalStack
2. **Verifica√ß√£o de cobertura** (60% reposit√≥rio, 40% c√≥digo novo)
3. **An√°lise SonarQube** com Quality Gates
4. **Scan de seguran√ßa** com gosec
5. **Build Docker** para ambientes dev e k8s
6. **Deploy autom√°tico** para staging/produ√ß√£o

### Configura√ß√£o SonarQube

Para usar SonarQube localmente:

1. Configure as vari√°veis de ambiente:
```bash
export SONAR_TOKEN=seu_token_sonarqube
export SONAR_HOST_URL=http://localhost:9000
```

2. Execute a an√°lise:
```bash
./test-coverage.sh
```

## ÔøΩüë• Autores

- **Bruno** - Desenvolvimento inicial e infraestrutura Kubernetes
- **Iana**  - Desenvolvimento inicial
- **Juliano** - Desenvolvimento inicial
- **Rafaelle** - Desenvolvimento inicial

---

**Nota**: Este projeto foi desenvolvido como parte do Hackathon FIAP e utiliza LocalStack para simular servi√ßos AWS em ambiente local.